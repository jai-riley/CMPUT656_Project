{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T1NX3D0_8vps"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet  langchain-google-genai pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from vertexai.preview.generative_models import (\n",
        "    HarmCategory,\n",
        "    HarmBlockThreshold )\n",
        "from google.cloud.aiplatform_v1beta1.types.content import SafetySetting\n",
        "import ast\n",
        "import os\n",
        "import getpass\n",
        "from vertexai.generative_models import GenerativeModel, ChatSession\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score\n",
        "import copy\n",
        "import re\n",
        "# from vertexai import generative_models\n"
      ],
      "metadata": {
        "id": "9yBXTzTo89s3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AIzaSyAEwNMlP_mg5oDc4Ut06CkUc_v7Ow_bAg4"
      ],
      "metadata": {
        "id": "guL28J30rSN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAEwNMlP_mg5oDc4Ut06CkUc_v7Ow_bAg4\" #getpass.getpass(\"Provide your Google API Key\")\n",
        "\n",
        "# safety_settings = [\n",
        "#     {\n",
        "#         \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "#         \"threshold\": \"BLOCK_NONE\",\n",
        "#     },\n",
        "#     {\n",
        "#         \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "#         \"threshold\": \"BLOCK_NONE\",\n",
        "#     },\n",
        "#     {\n",
        "#         \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "#         \"threshold\": \"BLOCK_NONE\",\n",
        "#     },\n",
        "#     {\n",
        "#         \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "#         \"threshold\": \"BLOCK_NONE\",\n",
        "#     },\n",
        "# ]\n",
        "\n",
        "# safety_settings = {\n",
        "#         generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
        "#         generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
        "#         generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_NONE,\n",
        "#         generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_NONE\n",
        "\n",
        "#     }"
      ],
      "metadata": {
        "id": "WcRDLK7L89p-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")"
      ],
      "metadata": {
        "id": "DVcLzbWFxRBo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MAVEN"
      ],
      "metadata": {
        "id": "ziPhAGsGjrQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAVEN_dataset = []"
      ],
      "metadata": {
        "id": "JzhknM9IbPzs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_events = ['Action', 'Arriving', 'Robbery', 'Preventing_or_letting', 'Kidnapping', 'Bodily_harm', 'Committing_crime', 'Temporary_stay', 'Writing', 'Commerce_sell', 'Recovering', 'Death', 'Cause_change_of_position_on_a_scale', 'Having_or_lacking_access', 'Participation', 'Reveal_secret', 'Competition', 'Extradition', 'Research', 'Wearing', 'Damaging', 'Hold', 'Carry_goods', 'Violence', 'Becoming', 'Labeling', 'Process_start', 'Justifying', 'Risk', 'Attack', 'Change_event_time', 'Bearing_arms', 'Conquering', 'Expressing_publicly', 'Employment', 'Presence', 'Prison', 'Quarreling', 'Emptying', 'Name_conferral', 'Change_of_leadership', 'Confronting_problem', 'Coming_to_believe', 'Expansion', 'Assistance', 'Placing', 'Arranging', 'Choosing', 'Traveling', 'Control', 'Testing', 'Military_operation', 'Bringing', 'Cost', 'Cause_to_amalgamate', 'Releasing', 'Protest', 'Aiming', 'Award', 'Imposing_obligation', 'Request', 'Connect', 'Judgment_communication', 'Destroying', 'Agree_or_refuse_to_act', 'Causation', 'Institutionalization', 'Adducing', 'Check', 'Response', 'Submitting_documents', 'Resolve_problem', 'Removing', 'Rewards_and_punishments', 'Dispersal', 'Terrorism', 'Scouring', 'Motion_directional', 'Patrolling', 'Scrutiny', 'Getting', 'Revenge', 'Ratification', 'Cure', 'Hindering', 'Cause_to_make_progress', 'Breathing', 'Commerce_pay', 'Supporting', 'Hiding_objects', 'Commitment', 'Telling', 'Change_sentiment', 'Emergency', 'Legality', 'Cause_change_of_strength', 'Forming_relationships', 'Coming_to_be', 'GetReady', 'Hostile_encounter', 'Lighting', 'Being_in_operation', 'Receiving', 'Building', 'Change_tool', 'Warning', 'Departing', 'Perception_active', 'Criminal_investigation', 'Communication', 'Suspicion', 'Exchange', 'Change', 'Education_teaching', 'Giving', 'Using', 'Manufacturing', 'Creating', 'Legal_rulings', 'Collaboration', 'Use_firearm', 'Publishing', 'Motion', 'Know', 'GiveUp', 'Escaping', 'Filling', 'Reporting', 'Create_artwork', 'Rescuing', 'Influence', 'Convincing', 'Reforming_a_system', 'Defending', 'Body_movement', 'Limiting', 'Cause_to_be_included', 'Practice', 'Catastrophe', 'Containing', 'Supply', 'Expend_resource', 'Surrendering', 'Sending', 'Vocalizations', 'Come_together', 'Earnings_and_losses', 'Preserving', 'Killing', 'Renting', 'Self_motion', 'Surrounding', 'Social_event', 'Arrest', 'Rite', 'Openness', 'Incident', 'Ingestion', 'Besieging', 'Process_end', 'Theft', 'Commerce_buy', 'Sign_agreement', 'Statement', 'Achieve', 'Becoming_a_member', 'Deciding', 'Recording']"
      ],
      "metadata": {
        "id": "s8BBoobrbNib"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "40 samples from MAVEN"
      ],
      "metadata": {
        "id": "SzVuEJF2b0zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAVEN_dataset_40samples = [\n",
        "{'sentence': \"French troops were sent into the area, as Général d'armée Maxime Weygand attempted to build up a defence in depth on the south bank of the Somme and make bigger attacks to eliminate the German bridgeheads.\", 'events': [{'Event_type': 'Sending', 'trigger_word': 'sent'}, {'Event_type': 'Building', 'trigger_word': 'build'}, {'Event_type': 'Creating', 'trigger_word': 'make'}, {'Event_type': 'Destroying', 'trigger_word': 'eliminate'}], 'id': 0},\n",
        "{'sentence': 'From the end of June to early September, over 3,000 forest fires were recorded across the nation.', 'events': [{'Event_type': 'Recording', 'trigger_word': 'recorded'}], 'id': 1},\n",
        "{'sentence': 'The invasion of Kuwait on 2 August 1990 was a two-day operation conducted by Iraq against the neighboring State of Kuwait, which resulted in the seven-month-long Iraqi occupation of the country.', 'events': [{'Event_type': 'Action', 'trigger_word': 'conducted'}, {'Event_type': 'Causation', 'trigger_word': 'resulted in'}], 'id': 2},\n",
        "{'sentence': 'Market Garden consisted of two sub operations: The attack was the largest airborne operation up to that point in World War II.', 'events': [{'Event_type': 'Attack', 'trigger_word': 'attack'}], 'id': 3},\n",
        "{'sentence': 'The hurricane continued to strengthen while developing a well-defined eye, and peaked as a Category 4 hurricane on September 11.', 'events': [{'Event_type': 'Cause_change_of_strength', 'trigger_word': 'strengthen'}, {'Event_type': 'Catastrophe', 'trigger_word': 'hurricane'}, {'Event_type': 'Self_motion', 'trigger_word': 'peaked'}], 'id': 4},\n",
        "{'sentence': 'A groundbreaking of the permanent memorial occurred in June 2006.', 'events': [{'Event_type': 'Social_event', 'trigger_word': 'memorial'}, {'Event_type': 'Presence', 'trigger_word': 'occurred'}], 'id': 5},\n",
        "{'sentence': 'As winners, Chelsea took part in the 2012 UEFA Super Cup, losing 4–1 to Atlético Madrid, the winners of the 2011–12 UEFA Europa League.', 'events': [{'Event_type': 'Earnings_and_losses', 'trigger_word': 'losing'}], 'id': 6},\n",
        "{'sentence': 'Two people died in the incident: the pilot, Pete Barnes, 50, and a pedestrian, Matthew Wood, 39, from Sutton in south London.', 'events': [{'Event_type': 'Death', 'trigger_word': 'died'}], 'id': 7},\n",
        "{'sentence': 'A series of meetings with the Conservatives began shortly after the hung parliament was announced, and continued over the weekend after the election.', 'events': [{'Event_type': 'Process_start', 'trigger_word': 'began'}, {'Event_type': 'Change_of_leadership', 'trigger_word': 'election'}, {'Event_type': 'Expressing_publicly', 'trigger_word': 'announced'}, {'Event_type': 'Social_event', 'trigger_word': 'meetings'}], 'id': 8},\n",
        "{'sentence': \"The festival's acts come from a wide range of genres, such as: electro, rock, drum and bass, pop, R&B, reggae, house, punk, hardcore, metal, hip-hop, indie, techno, and more.\", 'events': [{'Event_type': 'Social_event', 'trigger_word': 'festival'}, {'Event_type': 'Social_event', 'trigger_word': 'pop'}], 'id': 9},\n",
        "{'sentence': 'The chase was short, as \"Duguay Trouin\" was a poor sailor with many of the crew sick and unable to report for duty.', 'events': [{'Event_type': 'Self_motion', 'trigger_word': 'chase'}], 'id': 10},\n",
        "{'sentence': 'The ICTY convicted two JNA officers in connection with the massacre, and also tried former Serbian President Slobodan Milošević for a number of war crimes, including those committed at Vukovar.', 'events': [{'Event_type': 'Legal_rulings', 'trigger_word': 'convicted'}], 'id': 11},\n",
        "{'sentence': 'Weakening as it drifted inland, Winifred persisted as a tropical depression for another five days after landfall before finally dissipating on 5 February.', 'events': [{'Event_type': 'Motion', 'trigger_word': 'drifted'}, {'Event_type': 'Cause_change_of_strength', 'trigger_word': 'Weakening'}, {'Event_type': 'Arriving', 'trigger_word': 'landfall'}, {'Event_type': 'Wearing', 'trigger_word': 'persisted'}, {'Event_type': 'Removing', 'trigger_word': 'dissipating'}], 'id': 12},\n",
        "{'sentence': 'The whole community greets the Sun as they listen to Tibetan chants and guest musicians on the grassy hill.', 'events': [{'Event_type': 'Perception_active', 'trigger_word': 'listen'}, {'Event_type': 'Traveling', 'trigger_word': 'guest'}], 'id': 13},\n",
        "{'sentence': 'In Libya the Islamic State of Iraq and the Levant (ISIL) has been able to control some limited territory in the ongoing civil war since 2014, amid allegations of local collaboration between the otherwise rivalling AQIM and ISIL.', 'events': [{'Event_type': 'Control', 'trigger_word': 'control'}, {'Event_type': 'Limiting', 'trigger_word': 'limited'}, {'Event_type': 'Hostile_encounter', 'trigger_word': 'war'}], 'id': 14},\n",
        "{'sentence': 'The Inter-Provincial Series has been funded at least partly by the ICC via their TAPP programme.', 'events': [{'Event_type': 'Supply', 'trigger_word': 'funded'}], 'id': 15},\n",
        "{'sentence': 'The \"Struma\" disaster joined that of SS \"Patria\" – sunk after Haganah sabotage while laden with Jewish refugees 15 months earlier – as rallying points for the Irgun and Lehi revisionist Zionist clandestine movements, encouraging their violent revolt against the British presence in Palestine.', 'events': [{'Event_type': 'Change_of_leadership', 'trigger_word': 'revolt'}, {'Event_type': 'Becoming_a_member', 'trigger_word': 'joined'}, {'Event_type': 'Self_motion', 'trigger_word': 'sunk'}, {'Event_type': 'Bringing', 'trigger_word': 'laden'}], 'id': 16},\n",
        "{'sentence': 'On Friday, 28 February 1986, at 23:21 CET (22:21 UTC), Olof Palme, Prime Minister of Sweden, was fatally wounded by a single gunshot while walking home from a cinema with his wife Lisbet Palme on the central Stockholm street Sveavägen.', 'events': [{'Event_type': 'Bodily_harm', 'trigger_word': 'wounded'}, {'Event_type': 'Use_firearm', 'trigger_word': 'gunshot'}, {'Event_type': 'Self_motion', 'trigger_word': 'walking'}], 'id': 17},\n",
        "{'sentence': 'The Department of Social Security (DSS) sent employees to receive claims for damage, requests for financial aid, and filings for unemployment benefits.', 'events': [{'Event_type': 'Sending', 'trigger_word': 'sent'}, {'Event_type': 'Request', 'trigger_word': 'requests'}, {'Event_type': 'Receiving', 'trigger_word': 'receive'}, {'Event_type': 'Assistance', 'trigger_word': 'aid'}, {'Event_type': 'Employment', 'trigger_word': 'employees'}, {'Event_type': 'Earnings_and_losses', 'trigger_word': 'benefits'}, {'Event_type': 'Damaging', 'trigger_word': 'damage'}], 'id': 18},\n",
        "{'sentence': 'Air Algérie Flight 6289 (AH6289), was a domestic passenger flight which crashed on 6 March 2003, at the Aguenar – Hadj Bey Akhamok Airport in Algeria, killing all but one of the 103 people on board.', 'events': [{'Event_type': 'Catastrophe', 'trigger_word': 'crashed'}, {'Event_type': 'Killing', 'trigger_word': 'killing'}], 'id': 19},\n",
        "{'sentence': \"The accident is the RAF's worst peacetime disaster.\", 'events': [{'Event_type': 'Catastrophe', 'trigger_word': 'accident'}], 'id': 20},\n",
        "{'sentence': 'The governing Labour administration led by Gordon Brown was defeated in the election and lost its overall majority after 13 years in office.', 'events': [{'Event_type': 'Change_of_leadership', 'trigger_word': 'election'}, {'Event_type': 'Earnings_and_losses', 'trigger_word': 'lost'}, {'Event_type': 'Hostile_encounter', 'trigger_word': 'defeated'}], 'id': 21},\n",
        "{'sentence': 'The battle is mentioned in the Babylonian Chronicles, now housed in the British Museum.', 'events': [{'Event_type': 'Hostile_encounter', 'trigger_word': 'battle'}, {'Event_type': 'Statement', 'trigger_word': 'mentioned'}, {'Event_type': 'Containing', 'trigger_word': 'housed'}], 'id': 22},\n",
        "{'sentence': \"Nicolas Anelka of France scored the first goal in Club World Cup history, while Brazilian champions Corinthians' goalkeeper Dida posted the first official clean sheet in the tournament.\", 'events': [{'Event_type': 'Getting', 'trigger_word': 'scored'}, {'Event_type': 'Competition', 'trigger_word': 'champions'}, {'Event_type': 'Competition', 'trigger_word': 'tournament'}, {'Event_type': 'Sending', 'trigger_word': 'posted'}], 'id': 23},\n",
        "{'sentence': 'Hawthorn, who were competing in their inaugural VFL Grand Final despite being in the competition since 1925, came into the game as minor premiers and favourites.', 'events': [{'Event_type': 'Competition', 'trigger_word': 'competing'}, {'Event_type': 'Motion', 'trigger_word': 'came'}], 'id': 24},\n",
        "{'sentence': 'At the same time, General Joaquín Fanjul, commander of the military garrison based in Montaña barracks in Madrid, was preparing to launch the military rebellion in the city.', 'events': [{'Event_type': 'Process_start', 'trigger_word': 'launch'}, {'Event_type': 'GetReady', 'trigger_word': 'preparing'}], 'id': 25},\n",
        "{'sentence': 'The Engineers were said to have missed their best back, Lieut.', 'events': [{'Event_type': 'Communication', 'trigger_word': 'said'}, {'Event_type': 'Earnings_and_losses', 'trigger_word': 'missed'}], 'id': 26},\n",
        "{'sentence': 'They were organised on the initiative of deaf Frenchman Eugène Rubens-Alcais, who, just after the Games, co-founded the Comité International des Sports des Sourds with other \"deaf sporting leaders\".', 'events': [{'Event_type': 'Arranging', 'trigger_word': 'organised'}, {'Event_type': 'Collaboration', 'trigger_word': 'co-founded'}], 'id': 27},\n",
        "{'sentence': 'The impeachment trial was formally opened on November 20, with twenty-one senators taking their oaths as judges, and Supreme Court Chief Justice Hilario Davide, Jr. presiding.', 'events': [{'Event_type': 'Openness', 'trigger_word': 'opened'}], 'id': 28},\n",
        "{'sentence': 'The defense of Sihang Warehouse took place from October 26 to November 1, 1937, and marked the beginning of the end of the three-month Battle of Shanghai in the opening phase of the Second Sino-Japanese War.', 'events': [{'Event_type': 'Defending', 'trigger_word': 'defense'}, {'Event_type': 'Process_start', 'trigger_word': 'beginning'}, {'Event_type': 'Process_start', 'trigger_word': 'took place'}, {'Event_type': 'Recording', 'trigger_word': 'marked'}, {'Event_type': 'Process_end', 'trigger_word': 'end'}, {'Event_type': 'Hostile_encounter', 'trigger_word': 'Battle'}, {'Event_type': 'Hostile_encounter', 'trigger_word': 'War'}, {'Event_type': 'Openness', 'trigger_word': 'opening'}], 'id': 29},\n",
        "{'sentence': 'The attack failed, and a small raid that evening inflicted little damage.', 'events': [{'Event_type': 'Attack', 'trigger_word': 'attack'}, {'Event_type': 'Agree_or_refuse_to_act', 'trigger_word': 'failed'}, {'Event_type': 'Causation', 'trigger_word': 'inflicted'}], 'id': 30},\n",
        "{'sentence': \"The report cites research that shows people's feelings about a police encounter depend significantly on whether they feel the officer displays respect and courtesy.\", 'events': [{'Event_type': 'Change_sentiment', 'trigger_word': 'feel'}, {'Event_type': 'Adducing', 'trigger_word': 'cites'}, {'Event_type': 'Influence', 'trigger_word': 'depend'}], 'id': 31},\n",
        "{'sentence': 'Fighting continued for the next two days.', 'events': [{'Event_type': 'Hostile_encounter', 'trigger_word': 'Fighting'}], 'id': 32},\n",
        "{'sentence': 'On 19 March, he opened fire at the Ozar Hatorah Jewish day school in Toulouse, killing a rabbi and three children, also wounding four others.', 'events': [{'Event_type': 'Openness', 'trigger_word': 'opened'}, {'Event_type': 'Killing', 'trigger_word': 'killing'}], 'id': 33},\n",
        "{'sentence': 'Peace negotiations and foreign involvement led to a ceasefire in 1995 that was broken the next year before a final peace agreement and new national elections were held in 1997.', 'events': [{'Event_type': 'Communication', 'trigger_word': 'negotiations'}, {'Event_type': 'Participation', 'trigger_word': 'involvement'}, {'Event_type': 'Process_end', 'trigger_word': 'ceasefire'}, {'Event_type': 'Sign_agreement', 'trigger_word': 'agreement'}, {'Event_type': 'Change_of_leadership', 'trigger_word': 'elections'}, {'Event_type': 'Bodily_harm', 'trigger_word': 'broken'}, {'Event_type': 'Causation', 'trigger_word': 'led to'}], 'id': 34},\n",
        "{'sentence': 'On 2 August 1990 the Iraqi Army invaded and occupied Kuwait, which was met with international condemnation and brought immediate economic sanctions against Iraq by members of the UN Security Council.', 'events': [{'Event_type': 'Bringing', 'trigger_word': 'brought'}, {'Event_type': 'Attack', 'trigger_word': 'invaded'}, {'Event_type': 'Control', 'trigger_word': 'occupied'}, {'Event_type': 'Come_together', 'trigger_word': 'met with'}], 'id': 35},\n",
        "{'sentence': 'The Fall of Philadelphia marked the fall of Philadelphia, the last independent Christian Greek settlement in western Asia Minor, to the Muslim Turks of the Ottoman Sultanate.', 'events': [{'Event_type': 'Recording', 'trigger_word': 'marked'}, {'Event_type': 'Motion_directional', 'trigger_word': 'fall'}], 'id': 36},\n",
        "{'sentence': \"They see the Council's decision as part of a wider 'cultural war' against 'Britishness' in Northern Ireland.\", 'events': [{'Event_type': 'Deciding', 'trigger_word': 'decision'}, {'Event_type': 'Military_operation', 'trigger_word': 'war'}], 'id': 37},\n",
        "{'sentence': 'In the wake of the Polish advance eastward, the Soviets sued for peace and the war ended with a cease-fire in October 1920.', 'events': [{'Event_type': 'Process_end', 'trigger_word': 'ended'}, {'Event_type': 'Cause_to_make_progress', 'trigger_word': 'advance'}, {'Event_type': 'Hostile_encounter', 'trigger_word': 'war'}, {'Event_type': 'Request', 'trigger_word': 'sued'}], 'id': 38},\n",
        "{'sentence': 'Western fears of Soviet troops arriving at the German frontiers increased the interest of Western powers in the war.', 'events': [{'Event_type': 'Cause_change_of_position_on_a_scale', 'trigger_word': 'increased'}, {'Event_type': 'Arriving', 'trigger_word': 'arriving at'}, {'Event_type': 'Hostile_encounter', 'trigger_word': 'war'}], 'id': 39},\n",
        "]"
      ],
      "metadata": {
        "id": "eDEwGweEaUcs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_list_of_events = []\n",
        "for item in MAVEN_dataset_40samples:\n",
        "  for event in item['events']:\n",
        "    sample_list_of_events.append(event['Event_type'])\n",
        "sample_list_of_events = list(set(sample_list_of_events))\n"
      ],
      "metadata": {
        "id": "dsBHsc8Calmi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Event Extraction"
      ],
      "metadata": {
        "id": "dnGEtzKeBiR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General Setup"
      ],
      "metadata": {
        "id": "9s_WF5AKvwWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def EE_prompt_runner(prompt_base, dataset, list_of_events):\n",
        "  counter = 0\n",
        "  output_list = []\n",
        "  for idx, sample in enumerate(dataset):\n",
        "    prompt = prompt_base.format(list_of_events, sample['sentence'])\n",
        "    # print(prompt)\n",
        "    # output_list.append( {\"id\" : sample[\"id\"]})\n",
        "    try:\n",
        "      prediction = llm.invoke(prompt)\n",
        "      # print(output_list, idx)\n",
        "      answer =  prediction.content\n",
        "      # print(\"\\n **** \\n {} \\n **** \\n\".format(answer))\n",
        "      if \"Event type: \" not in  answer:\n",
        "          answer = \"Event type: \" + answer\n",
        "      # print(prompt)\n",
        "      output_list.append( {\"id\" : sample[\"id\"], 'prediction':answer })\n",
        "      # output_list[idx]['prediction'] = answer\n",
        "      counter += 1\n",
        "    except Exception as e:\n",
        "      # print(e)\n",
        "      print('error for sentence: ', sample['sentence'])\n",
        "      # output_list[idx]['prediction'] =  'error'\n",
        "    if counter == 20:\n",
        "      break\n",
        "\n",
        "  return output_list"
      ],
      "metadata": {
        "id": "j4h_1rMau48x"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def EE_output_processing(org_output):\n",
        "  output = copy.deepcopy(org_output)\n",
        "  # remove empty list samples\n",
        "  output = [item for item in output if len(item.keys())>= 2]\n",
        "  # for sample in output:\n",
        "  #   if len(sample.keys()) < 2:\n",
        "  #     output.remove(sample)\n",
        "  # print(output)\n",
        "\n",
        "  for sample in output:\n",
        "    sample['prediction'] = [ item.strip() for item in sample['prediction'].split(\"Event type: \")[1].strip().split(',')]\n",
        "  return output"
      ],
      "metadata": {
        "id": "uXFrJRMzn6Uy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def EE_gold_samples_generator(MAVAN_dataset):\n",
        "  gold_samples = {}\n",
        "  for sample in MAVAN_dataset:\n",
        "    # gold_sample = {}\n",
        "    gold_samples[sample['id']] = [event['Event_type'] for event in  sample['events']]\n",
        "    # gold_samples.append(gold_sample)\n",
        "  return gold_samples"
      ],
      "metadata": {
        "id": "uvke66wpn6Ni"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reorder_lists(list1, list2):\n",
        "    # Combine the input lists and find unique elements\n",
        "    merged_list = list1 + list2\n",
        "    unique_elements = list(set(merged_list))\n",
        "\n",
        "    # Create placeholders for elements not present in each list\n",
        "    reordered_list1 = []\n",
        "    reordered_list2 = []\n",
        "    for element in unique_elements:\n",
        "        if element in list1 and element in list2:\n",
        "            reordered_list1.append(element)\n",
        "            reordered_list2.append(element)\n",
        "        elif element in list1:\n",
        "            reordered_list1.append(element)\n",
        "            reordered_list2.append(\"0\")\n",
        "        elif element in list2:\n",
        "            reordered_list1.append(\"0\")\n",
        "            reordered_list2.append(element)\n",
        "\n",
        "    return reordered_list1, reordered_list2"
      ],
      "metadata": {
        "id": "NueuRNxkn6EE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def EE_evaluation(gold_samples, processed_output):\n",
        "  labels = []\n",
        "  predictions = []\n",
        "\n",
        "  for item in processed_output:\n",
        "    # print(item['prediction'])\n",
        "    # print(gold_samples[item['id']])\n",
        "    # print(\"\\n *** \\n \")\n",
        "    gold, pred = reorder_lists(gold_samples[item['id']] ,item['prediction'])\n",
        "    labels.extend(gold)\n",
        "    predictions.extend(pred)\n",
        "\n",
        "  return labels, predictions"
      ],
      "metadata": {
        "id": "g5XwBQcqoUga"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def EE_metric_calculation(labels, predictions, event_labels):\n",
        "\n",
        "  # When predicting an event not present in the ground truth, our predictions are incorrect, resulting in a decrease in our Precision (P).\n",
        "  # If we fail to predict any event when one exists in the ground truth, it decreases our Recall (R).\n",
        "  #This is why we include zeros in both the ground truth and prediction lists, to address the inconsistency in the number of extracted events.\"\n",
        "\n",
        "  micro_p = precision_score(labels,predictions, labels = event_labels,average='micro')*100.0\n",
        "  micro_r = recall_score(labels,predictions, labels = event_labels, average='micro')*100.0\n",
        "  micro_f1 = f1_score(labels,predictions, labels = event_labels, average='micro')*100.0\n",
        "\n",
        "\n",
        "  print(\"Micro_F1:\",micro_f1)\n",
        "  print(\"Micro_Precision:\",micro_p)\n",
        "  print(\"Micro_Recall:\",micro_r)\n",
        "\n",
        "\n",
        "  # macro_p=precision_score(labels,predictions,labels = event_labels,average='macro')*100.0\n",
        "  # macro_r=recall_score(labels,predictions,labels = event_labels,average='macro')*100.0\n",
        "  # macro_f1=f1_score(labels,predictions,labels = event_labels,average='macro')*100.0\n",
        "\n",
        "\n",
        "  # print(\"Macro_F1:\",macro_f1)\n",
        "  # print(\"Macro_Precision:\",macro_p)\n",
        "  # print(\"Macro_Recall:\",macro_r)\n"
      ],
      "metadata": {
        "id": "fRfn3Hqwp25T"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ],
      "metadata": {
        "id": "5dnBv0jvom1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gold_samples = EE_gold_samples_generator(MAVEN_dataset_40samples)"
      ],
      "metadata": {
        "id": "JVzcV0_3sHqE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline Prompts"
      ],
      "metadata": {
        "id": "_9H-9OOspSf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EE_zero_shot_paper = '''\n",
        "The list of event types: {}\n",
        "Give a sentence: French troops were sent into the area, as Général d'armée Maxime Weygand attempted to build up a defence in depth on the south bank of the Somme and make bigger attacks to eliminate the German bridgeheads.\n",
        "What types of events are included in this sentence? Please return the most likely answer according to the list of event types above. Require the answer in the form: Event type\n",
        "Give a sentence: {}\n",
        "Event type:\n",
        "'''\n",
        "\n",
        "EE_one_shot_paper = '''\n",
        "The list of event types: {}\n",
        "What types of events are included in the following sentence? Please return the most likely answer according to the list of event types above. Require the answer in the form: Event type.Ensure that the extracted event is included in the prepared list.\n",
        "Example:\n",
        "\n",
        "Give a sentence: French troops were sent into the area, as Général d'armée Maxime Weygand attempted to build up a defence in depth on the south bank of the Somme and make bigger attacks to eliminate the German bridgeheads.\n",
        "Event type: Sending, Building, Creating, Destroying\n",
        "\n",
        "Give a sentence: {}\n",
        "Event type:\n",
        "'''\n"
      ],
      "metadata": {
        "id": "bwn4aZCEpREL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Replicating Paper results"
      ],
      "metadata": {
        "id": "BBexxuEOpiRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero_Shot\n",
        "output = EE_prompt_runner(EE_zero_shot_paper, MAVEN_dataset_40samples, sample_list_of_events)\n",
        "processed_output = EE_output_processing(output)\n",
        "labels, predictions = EE_evaluation(gold_samples, processed_output)\n",
        "EE_metric_calculation(labels, predictions, sample_list_of_events)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fbb6KtLmYRgC",
        "outputId": "ac6c50a7-54f8-4c51-f58f-4a97ae8f0d8f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error for sentence:  Two people died in the incident: the pilot, Pete Barnes, 50, and a pedestrian, Matthew Wood, 39, from Sutton in south London.\n",
            "error for sentence:  The ICTY convicted two JNA officers in connection with the massacre, and also tried former Serbian President Slobodan Milošević for a number of war crimes, including those committed at Vukovar.\n",
            "error for sentence:  The \"Struma\" disaster joined that of SS \"Patria\" – sunk after Haganah sabotage while laden with Jewish refugees 15 months earlier – as rallying points for the Irgun and Lehi revisionist Zionist clandestine movements, encouraging their violent revolt against the British presence in Palestine.\n",
            "error for sentence:  On Friday, 28 February 1986, at 23:21 CET (22:21 UTC), Olof Palme, Prime Minister of Sweden, was fatally wounded by a single gunshot while walking home from a cinema with his wife Lisbet Palme on the central Stockholm street Sveavägen.\n",
            "Micro_F1: 8.421052631578947\n",
            "Micro_Precision: 8.88888888888889\n",
            "Micro_Recall: 8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One_Shot\n",
        "output = EE_prompt_runner(EE_one_shot_paper, MAVEN_dataset_40samples, sample_list_of_events)\n",
        "processed_output = EE_output_processing(output)\n",
        "labels, predictions = EE_evaluation(gold_samples, processed_output)\n",
        "EE_metric_calculation(labels, predictions, sample_list_of_events)"
      ],
      "metadata": {
        "id": "ext2gVFoxVzA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec19df49-26fd-48f2-a32a-93dfb5d062f9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error for sentence:  French troops were sent into the area, as Général d'armée Maxime Weygand attempted to build up a defence in depth on the south bank of the Somme and make bigger attacks to eliminate the German bridgeheads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error for sentence:  On Friday, 28 February 1986, at 23:21 CET (22:21 UTC), Olof Palme, Prime Minister of Sweden, was fatally wounded by a single gunshot while walking home from a cinema with his wife Lisbet Palme on the central Stockholm street Sveavägen.\n",
            "Micro_F1: 24.615384615384617\n",
            "Micro_Precision: 47.05882352941176\n",
            "Micro_Recall: 16.666666666666664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trying designed CoT prompt"
      ],
      "metadata": {
        "id": "PvFE2XQ_tf3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EE_cot_one_shot1 = '''\n",
        "\n",
        "Analyze the provided sentence step by step to extract the event types:\n",
        "\n",
        "Step 1: Recognize Trigger Words: Trigger words are terms or phrases indicating the start or occurrence of events within a text or context.\n",
        "Step 2: Match each trigger word with the most relevant event type from the list of events. The list of event types: {}\n",
        "output: Format the output by listing the event types separated by commas after the keyword \"Event type: \"\n",
        "\n",
        "example:\n",
        "\n",
        "provided sentence: French troops were sent into the area, as Général d'armée Maxime Weygand attempted to build up a defence in depth on the south bank of the Somme and make bigger attacks to eliminate the German bridgeheads.\n",
        "\n",
        "Step1: triger words: <sent>, <build>, <make>, <eliminate>\n",
        "\n",
        "Step2:\n",
        "For the trigger word <sent>, the most related event among events in the Event list is <Sending>.\n",
        "For the trigger word <build>, the most related event among events in the Event list is <Building>.\n",
        "For the trigger word <make>, the most related event among events in the Event list is <Creating>.\n",
        "For the trigger word <eliminate>, the most related event among events in the Event list is <Destroying>.\n",
        "\n",
        "Event type: Sending, Building, Creating, Destroying\n",
        "\n",
        "provided sentence: {}\n",
        "'''"
      ],
      "metadata": {
        "id": "3B1E9L7qtlrr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = EE_prompt_runner(EE_cot_one_shot1, MAVEN_dataset_40samples, sample_list_of_events)\n",
        "processed_output = EE_output_processing(output)\n",
        "labels, predictions = EE_evaluation(gold_samples, processed_output)\n",
        "EE_metric_calculation(labels, predictions, sample_list_of_events)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpUYkQRetWmS",
        "outputId": "04f415ff-700c-4a43-d798-2b0497fa09ec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Micro_F1: 55.55555555555556\n",
            "Micro_Precision: 60.97560975609756\n",
            "Micro_Recall: 51.02040816326531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Triple Extraction"
      ],
      "metadata": {
        "id": "8GNZixamV9Rt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RE-TACRED Dataset"
      ],
      "metadata": {
        "id": "wfBtcEKJrO2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SciERC Daatset"
      ],
      "metadata": {
        "id": "fmhnFsRF2OIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SciERC_dataset_40samples = [\n",
        "{'relation': 'PART-OF', 'tokens': 'Learned confidence measures gain increasing importance for outlier removal and quality improvement in stereo vision .', 'h': {'name': 'outlier removal', 'pos': [7, 9]}, 't': {'name': 'stereo vision', 'pos': [13, 15]}, 'id': 0},\n",
        "{'relation': 'CONJUNCTION', 'tokens': \"We test our algorithm on the detection task and the viewpoint classification task by using '' car '' category from both the Savarese et al. 2007 and PASCAL VOC 2006 datasets .\", 'h': {'name': 'detection task', 'pos': [6, 8]}, 't': {'name': 'viewpoint classification task', 'pos': [10, 13]}, 'id': 1},\n",
        "{'relation': 'CONJUNCTION', 'tokens': 'This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .', 'h': {'name': 'trees', 'pos': [16, 17]}, 't': {'name': 'dags', 'pos': [18, 19]}, 'id': 2},\n",
        "{'relation': 'EVALUATE-FOR', 'tokens': 'Experiments on synthetic and real data show that both our triangulation and LAGC algorithms outperform state-of-the-art solutions in accuracy and visual quality .', 'h': {'name': 'visual quality', 'pos': [20, 22]}, 't': {'name': 'state-of-the-art solutions', 'pos': [15, 17]}, 'id': 3},\n",
        "{'relation': 'USED-FOR', 'tokens': 'These methods diier from previous work in the area in two ways : the use of an action model formalism which is better suited to the needs of a re-active agent , and successful implementation of noise-handling mechanisms .', 'h': {'name': 'action model formalism', 'pos': [17, 20]}, 't': {'name': 'methods', 'pos': [1, 2]}, 'id': 4},\n",
        "{'relation': 'PART-OF', 'tokens': 'Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .', 'h': {'name': 'latent variables', 'pos': [22, 24]}, 't': {'name': 'multinomial distribution', 'pos': [17, 19]}, 'id': 5},\n",
        "{'relation': 'FEATURE-OF', 'tokens': 'Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .', 'h': {'name': 'minimal overhead', 'pos': [45, 47]}, 't': {'name': 'Gaussian models', 'pos': [42, 44]}, 'id': 6},\n",
        "{'relation': 'USED-FOR', 'tokens': 'Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .', 'h': {'name': 'maximum-entropy model', 'pos': [23, 25]}, 't': {'name': 'stochastic output selection', 'pos': [26, 29]}, 'id': 7},\n",
        "{'relation': 'PART-OF', 'tokens': 'Using this approach , we extract parallel data from large Chinese , Arabic , and English non-parallel newspaper corpora .', 'h': {'name': 'parallel data', 'pos': [6, 8]}, 't': {'name': 'Chinese , Arabic , and English non-parallel newspaper corpora', 'pos': [10, 19]}, 'id': 8},\n",
        "{'relation': 'USED-FOR', 'tokens': 'It is presented as a generalization of the recursive descent parser .', 'h': {'name': 'recursive descent parser', 'pos': [8, 11]}, 't': {'name': 'It', 'pos': [0, 1]}, 'id': 9},\n",
        "{'relation': 'PART-OF', 'tokens': 'Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .', 'h': {'name': 'transfer component', 'pos': [10, 12]}, 't': {'name': 'system', 'pos': [1, 2]}, 'id': 10},\n",
        "{'relation': 'CONJUNCTION', 'tokens': 'The task of machine translation -LRB- MT -RRB- evaluation is closely related to the task of sentence-level semantic equivalence classification .', 'h': {'name': 'machine translation -LRB- MT -RRB- evaluation', 'pos': [3, 9]}, 't': {'name': 'sentence-level semantic equivalence classification', 'pos': [16, 20]}, 'id': 11},\n",
        "{'relation': 'USED-FOR', 'tokens': 'In this paper , we discuss language model adaptation methods given a word list and a raw corpus .', 'h': {'name': 'word list', 'pos': [12, 14]}, 't': {'name': 'language model adaptation methods', 'pos': [6, 10]}, 'id': 12},\n",
        "{'relation': 'EVALUATE-FOR', 'tokens': 'Experiments on the PASCAL VOC 2006 dataset show an acceleration of more than 50 % by our method compared to standard cascade evaluation .', 'h': {'name': 'PASCAL VOC 2006 dataset', 'pos': [3, 7]}, 't': {'name': 'cascade evaluation', 'pos': [21, 23]}, 'id': 13},\n",
        "{'relation': 'USED-FOR', 'tokens': 'Compared to the exhaustive procedure that thus far is the state-of-the-art for cascade evaluation , the proposed method requires fewer evaluations of the classifier functions , thereby speeding up the search .', 'h': {'name': 'method', 'pos': [17, 18]}, 't': {'name': 'search', 'pos': [30, 31]}, 'id': 14},\n",
        "{'relation': 'USED-FOR', 'tokens': 'Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space .', 'h': {'name': 'algorithm', 'pos': [7, 8]}, 't': {'name': 'rendering of occlusions', 'pos': [19, 22]}, 'id': 15},\n",
        "{'relation': 'CONJUNCTION', 'tokens': 'Our numerical hybrid local and global mode-seeking tracker is validated on challenging airborne videos with heavy occlusion and large camera motions .', 'h': {'name': 'heavy occlusion', 'pos': [15, 17]}, 't': {'name': 'camera motions', 'pos': [19, 21]}, 'id': 16},\n",
        "{'relation': 'USED-FOR', 'tokens': 'We propose to incorporate a priori geometric constraints in a 3 -- D stereo reconstruction scheme to cope with the many cases where image information alone is not sufficient to accurately recover 3 -- D shape .', 'h': {'name': 'image information', 'pos': [23, 25]}, 't': {'name': '3 -- D shape', 'pos': [32, 36]}, 'id': 17},\n",
        "{'relation': 'USED-FOR', 'tokens': 'It is demonstrated qualitatively and quantitatively on a dataset of scenes and is suitable for current work in unsupervised object discovery without top-down knowledge .', 'h': {'name': 'It', 'pos': [0, 1]}, 't': {'name': 'unsupervised object discovery', 'pos': [18, 21]}, 'id': 18},\n",
        "{'relation': 'USED-FOR', 'tokens': 'Starting from a DP-based solution to the traveling salesman problem , we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an efficient search algorithm .', 'h': {'name': 'technique', 'pos': [15, 16]}, 't': {'name': 'search algorithm', 'pos': [33, 35]}, 'id': 19},\n",
        "{'relation': 'HYPONYM-OF', 'tokens': 'Topical blog post retrieval is the task of ranking blog posts with respect to their relevance for a given topic .', 'h': {'name': 'Topical blog post retrieval', 'pos': [0, 4]}, 't': {'name': 'ranking blog posts', 'pos': [8, 11]}, 'id': 20},\n",
        "{'relation': 'USED-FOR', 'tokens': 'Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .', 'h': {'name': 'logistic stick-breaking representation', 'pos': [5, 8]}, 't': {'name': 'multinomial distribution', 'pos': [17, 19]}, 'id': 21},\n",
        "{'relation': 'PART-OF', 'tokens': 'We analyzed eye gaze , head nods and attentional focus in the context of a direction-giving task .', 'h': {'name': 'eye gaze', 'pos': [2, 4]}, 't': {'name': 'direction-giving task', 'pos': [15, 17]}, 'id': 22},\n",
        "{'relation': 'HYPONYM-OF', 'tokens': 'We examine the relationship between the two grammatical formalisms : Tree Adjoining Grammars and Head Grammars .', 'h': {'name': 'Head Grammars', 'pos': [14, 16]}, 't': {'name': 'grammatical formalisms', 'pos': [7, 9]}, 'id': 23},\n",
        "{'relation': 'CONJUNCTION', 'tokens': 'The objective of this work is to recognize faces using video sequences both for training and recognition input , in a realistic , unconstrained setup in which lighting , pose and user motion pattern have a wide variability and face images are of low resolution .', 'h': {'name': 'pose', 'pos': [29, 30]}, 't': {'name': 'user motion pattern', 'pos': [31, 34]}, 'id': 24},\n",
        "{'relation': 'USED-FOR', 'tokens': 'In this paper , we present our work on the detection of question-answer pairs in an email conversation for the task of email summarization .', 'h': {'name': 'email conversation', 'pos': [16, 18]}, 't': {'name': 'detection of question-answer pairs', 'pos': [10, 14]}, 'id': 25},\n",
        "{'relation': 'USED-FOR', 'tokens': 'Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space .', 'h': {'name': 'algorithm', 'pos': [7, 8]}, 't': {'name': 'temporal maintenance of a background model', 'pos': [10, 16]}, 'id': 26},\n",
        "{'relation': 'USED-FOR', 'tokens': 'They improve the reconstruction results and enforce their consistency with a priori knowledge about object shape .', 'h': {'name': 'They', 'pos': [0, 1]}, 't': {'name': 'reconstruction', 'pos': [3, 4]}, 'id': 27},\n",
        "{'relation': 'HYPONYM-OF', 'tokens': 'MINPRAN , a new robust operator , nds good ts in data sets where more than 50 % of the points are outliers .', 'h': {'name': 'MINPRAN', 'pos': [0, 1]}, 't': {'name': 'robust operator', 'pos': [4, 6]}, 'id': 28},\n",
        "{'relation': 'USED-FOR', 'tokens': 'Recent progress in computer vision has been driven by high-capacity models trained on large datasets .', 'h': {'name': 'high-capacity models', 'pos': [9, 11]}, 't': {'name': 'computer vision', 'pos': [3, 5]}, 'id': 29},\n",
        "{'relation': 'COMPARE', 'tokens': 'Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .', 'h': {'name': 'trainable components', 'pos': [27, 29]}, 't': {'name': 'hand-crafted template-based or rule-based approaches', 'pos': [32, 37]}, 'id': 30},\n",
        "{'relation': 'USED-FOR', 'tokens': 'To a large extent , these statistics reflect semantic constraints and thus are used to disambiguate anaphora references and syntactic ambiguities .', 'h': {'name': 'semantic constraints', 'pos': [8, 10]}, 't': {'name': 'anaphora references', 'pos': [16, 18]}, 'id': 31},\n",
        "{'relation': 'USED-FOR', 'tokens': 'This paper solves a specialized regression problem to obtain sampling probabilities for records in databases .', 'h': {'name': 'sampling probabilities', 'pos': [9, 11]}, 't': {'name': 'records', 'pos': [12, 13]}, 'id': 32},\n",
        "{'relation': 'FEATURE-OF', 'tokens': 'We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination , pose and head motion variation .', 'h': {'name': 'illumination', 'pos': [26, 27]}, 't': {'name': 'video sequences', 'pos': [22, 24]}, 'id': 33},\n",
        "{'relation': 'USED-FOR', 'tokens': 'Based on these results , we present an ECA that uses verbal and nonverbal grounding acts to update dialogue state .', 'h': {'name': 'verbal and nonverbal grounding acts', 'pos': [11, 16]}, 't': {'name': 'dialogue state', 'pos': [18, 20]}, 'id': 34},\n",
        "{'relation': 'EVALUATE-FOR', 'tokens': 'Unlike existing interest point detectors , which measure pixel-wise differences in image intensity , our detectors incorporate histogram-based representations , and thus can find image regions that present a distinct distribution in the neighborhood .', 'h': {'name': 'pixel-wise differences in image intensity', 'pos': [8, 13]}, 't': {'name': 'interest point detectors', 'pos': [2, 5]}, 'id': 35},\n",
        "{'relation': 'USED-FOR', 'tokens': 'Our study reveals that the syntactic structure features embedded in a parse tree are very effective for relation extraction and these features can be well captured by the convolution tree kernel .', 'h': {'name': 'convolution tree kernel', 'pos': [28, 31]}, 't': {'name': 'features', 'pos': [21, 22]}, 'id': 36},\n",
        "{'relation': 'USED-FOR', 'tokens': 'A new tool for linguistic annotation of scfs in corpus data is also introduced which can considerably alleviate the process of obtaining training and test data for subcategorization acquisition .', 'h': {'name': 'training and test data', 'pos': [22, 26]}, 't': {'name': 'subcategorization acquisition', 'pos': [27, 29]}, 'id': 37},\n",
        "{'relation': 'USED-FOR', 'tokens': 'We propose a novel probabilistic framework for learning visual models of 3D object categories by combining appearance information and geometric constraints .', 'h': {'name': 'geometric constraints', 'pos': [19, 21]}, 't': {'name': 'probabilistic framework', 'pos': [4, 6]}, 'id': 38},\n",
        "{'relation': 'CONJUNCTION', 'tokens': 'Experimental results on our dataset and the public G3D dataset both demonstrate very promising performance of our scheme .', 'h': {'name': 'dataset', 'pos': [4, 5]}, 't': {'name': 'G3D dataset', 'pos': [8, 10]}, 'id': 39},\n",
        "]"
      ],
      "metadata": {
        "id": "88CQuKi4WA9q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sample in SciERC_dataset_40samples:\n",
        "  print( sample['h']['name'], \"-\" , sample['relation'], \"-\", sample['t']['name'], \" ||||  sentence: \", sample['tokens'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4drH7K_5U-El",
        "outputId": "17b517d8-a429-450f-b344-e8c54937a5fb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "outlier removal - PART-OF - stereo vision  ||||  sentence:  Learned confidence measures gain increasing importance for outlier removal and quality improvement in stereo vision .\n",
            "detection task - CONJUNCTION - viewpoint classification task  ||||  sentence:  We test our algorithm on the detection task and the viewpoint classification task by using '' car '' category from both the Savarese et al. 2007 and PASCAL VOC 2006 datasets .\n",
            "trees - CONJUNCTION - dags  ||||  sentence:  This paper proposes a generic mathematical formalism for the combination of various structures : strings , trees , dags , graphs , and products of them .\n",
            "visual quality - EVALUATE-FOR - state-of-the-art solutions  ||||  sentence:  Experiments on synthetic and real data show that both our triangulation and LAGC algorithms outperform state-of-the-art solutions in accuracy and visual quality .\n",
            "action model formalism - USED-FOR - methods  ||||  sentence:  These methods diier from previous work in the area in two ways : the use of an action model formalism which is better suited to the needs of a re-active agent , and successful implementation of noise-handling mechanisms .\n",
            "latent variables - PART-OF - multinomial distribution  ||||  sentence:  Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .\n",
            "minimal overhead - FEATURE-OF - Gaussian models  ||||  sentence:  Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .\n",
            "maximum-entropy model - USED-FOR - stochastic output selection  ||||  sentence:  Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .\n",
            "parallel data - PART-OF - Chinese , Arabic , and English non-parallel newspaper corpora  ||||  sentence:  Using this approach , we extract parallel data from large Chinese , Arabic , and English non-parallel newspaper corpora .\n",
            "recursive descent parser - USED-FOR - It  ||||  sentence:  It is presented as a generalization of the recursive descent parser .\n",
            "transfer component - PART-OF - system  ||||  sentence:  Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection .\n",
            "machine translation -LRB- MT -RRB- evaluation - CONJUNCTION - sentence-level semantic equivalence classification  ||||  sentence:  The task of machine translation -LRB- MT -RRB- evaluation is closely related to the task of sentence-level semantic equivalence classification .\n",
            "word list - USED-FOR - language model adaptation methods  ||||  sentence:  In this paper , we discuss language model adaptation methods given a word list and a raw corpus .\n",
            "PASCAL VOC 2006 dataset - EVALUATE-FOR - cascade evaluation  ||||  sentence:  Experiments on the PASCAL VOC 2006 dataset show an acceleration of more than 50 % by our method compared to standard cascade evaluation .\n",
            "method - USED-FOR - search  ||||  sentence:  Compared to the exhaustive procedure that thus far is the state-of-the-art for cascade evaluation , the proposed method requires fewer evaluations of the classifier functions , thereby speeding up the search .\n",
            "algorithm - USED-FOR - rendering of occlusions  ||||  sentence:  Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space .\n",
            "heavy occlusion - CONJUNCTION - camera motions  ||||  sentence:  Our numerical hybrid local and global mode-seeking tracker is validated on challenging airborne videos with heavy occlusion and large camera motions .\n",
            "image information - USED-FOR - 3 -- D shape  ||||  sentence:  We propose to incorporate a priori geometric constraints in a 3 -- D stereo reconstruction scheme to cope with the many cases where image information alone is not sufficient to accurately recover 3 -- D shape .\n",
            "It - USED-FOR - unsupervised object discovery  ||||  sentence:  It is demonstrated qualitatively and quantitatively on a dataset of scenes and is suitable for current work in unsupervised object discovery without top-down knowledge .\n",
            "technique - USED-FOR - search algorithm  ||||  sentence:  Starting from a DP-based solution to the traveling salesman problem , we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an efficient search algorithm .\n",
            "Topical blog post retrieval - HYPONYM-OF - ranking blog posts  ||||  sentence:  Topical blog post retrieval is the task of ranking blog posts with respect to their relevance for a given topic .\n",
            "logistic stick-breaking representation - USED-FOR - multinomial distribution  ||||  sentence:  Here , we leverage a logistic stick-breaking representation and recent innovations in Pólya-gamma augmentation to reformu-late the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods , enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead .\n",
            "eye gaze - PART-OF - direction-giving task  ||||  sentence:  We analyzed eye gaze , head nods and attentional focus in the context of a direction-giving task .\n",
            "Head Grammars - HYPONYM-OF - grammatical formalisms  ||||  sentence:  We examine the relationship between the two grammatical formalisms : Tree Adjoining Grammars and Head Grammars .\n",
            "pose - CONJUNCTION - user motion pattern  ||||  sentence:  The objective of this work is to recognize faces using video sequences both for training and recognition input , in a realistic , unconstrained setup in which lighting , pose and user motion pattern have a wide variability and face images are of low resolution .\n",
            "email conversation - USED-FOR - detection of question-answer pairs  ||||  sentence:  In this paper , we present our work on the detection of question-answer pairs in an email conversation for the task of email summarization .\n",
            "algorithm - USED-FOR - temporal maintenance of a background model  ||||  sentence:  Furthermore , this paper presents a novel algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts -LRB- flicker -RRB- ; and a cost aggregation algorithm that acts directly on our three-dimensional matching cost space .\n",
            "They - USED-FOR - reconstruction  ||||  sentence:  They improve the reconstruction results and enforce their consistency with a priori knowledge about object shape .\n",
            "MINPRAN - HYPONYM-OF - robust operator  ||||  sentence:  MINPRAN , a new robust operator , nds good ts in data sets where more than 50 % of the points are outliers .\n",
            "high-capacity models - USED-FOR - computer vision  ||||  sentence:  Recent progress in computer vision has been driven by high-capacity models trained on large datasets .\n",
            "trainable components - COMPARE - hand-crafted template-based or rule-based approaches  ||||  sentence:  Techniques for automatically training modules of a natural language generator have recently been proposed , but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches .\n",
            "semantic constraints - USED-FOR - anaphora references  ||||  sentence:  To a large extent , these statistics reflect semantic constraints and thus are used to disambiguate anaphora references and syntactic ambiguities .\n",
            "sampling probabilities - USED-FOR - records  ||||  sentence:  This paper solves a specialized regression problem to obtain sampling probabilities for records in databases .\n",
            "illumination - FEATURE-OF - video sequences  ||||  sentence:  We describe a fully automatic recognition system based on the proposed method and an extensive evaluation on 171 individuals and over 1300 video sequences with extreme illumination , pose and head motion variation .\n",
            "verbal and nonverbal grounding acts - USED-FOR - dialogue state  ||||  sentence:  Based on these results , we present an ECA that uses verbal and nonverbal grounding acts to update dialogue state .\n",
            "pixel-wise differences in image intensity - EVALUATE-FOR - interest point detectors  ||||  sentence:  Unlike existing interest point detectors , which measure pixel-wise differences in image intensity , our detectors incorporate histogram-based representations , and thus can find image regions that present a distinct distribution in the neighborhood .\n",
            "convolution tree kernel - USED-FOR - features  ||||  sentence:  Our study reveals that the syntactic structure features embedded in a parse tree are very effective for relation extraction and these features can be well captured by the convolution tree kernel .\n",
            "training and test data - USED-FOR - subcategorization acquisition  ||||  sentence:  A new tool for linguistic annotation of scfs in corpus data is also introduced which can considerably alleviate the process of obtaining training and test data for subcategorization acquisition .\n",
            "geometric constraints - USED-FOR - probabilistic framework  ||||  sentence:  We propose a novel probabilistic framework for learning visual models of 3D object categories by combining appearance information and geometric constraints .\n",
            "dataset - CONJUNCTION - G3D dataset  ||||  sentence:  Experimental results on our dataset and the public G3D dataset both demonstrate very promising performance of our scheme .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_relation = []\n",
        "for item in SciERC_dataset_40samples:\n",
        "  list_of_relation.append(item['relation'])\n",
        "\n",
        "list_of_relations = list(set(list_of_relation))"
      ],
      "metadata": {
        "id": "JGjM_Mvv4T3N"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General Setups"
      ],
      "metadata": {
        "id": "xOuee0HF4Xd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_triples(text):\n",
        "    triples = []\n",
        "    pattern = r'\\[([^\\[\\]]+)\\]'\n",
        "    matches = re.findall(pattern, text)\n",
        "    for match in matches:\n",
        "        triple = [elem.strip() for elem in match.split(',')]\n",
        "        triples.append(triple)\n",
        "    return triples"
      ],
      "metadata": {
        "id": "stAzmzZvd8C8"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TE_prompt_runner(prompt_base, dataset, list_of_relations):\n",
        "  counter = 0\n",
        "  output_list = []\n",
        "  for idx, sample in enumerate(dataset):\n",
        "    prompt = prompt_base.format(list_of_relations, sample['tokens'])\n",
        "    # print(prompt)\n",
        "\n",
        "    try:\n",
        "      prediction = llm.invoke(prompt)\n",
        "      # print(output_list, idx)\n",
        "      answer =  prediction.content\n",
        "      # print(\"\\n **** \\n {} \\n **** \\n\".format(answer))\n",
        "      # if \"Triples: \" not in  answer:\n",
        "      #     answer = \"Triples: \" + answer\n",
        "      output_list.append( {\"id\" : sample[\"id\"], 'Triples': extract_triples(answer)})\n",
        "      # print(prompt)\n",
        "      # output_list[idx]['Triples'] = extract_triples(answer)\n",
        "      counter += 1\n",
        "    except Exception as e:\n",
        "      # print(e)\n",
        "      print('error for sentence: ', sample['tokens'])\n",
        "      # output_list[idx]['prediction'] =  'error'\n",
        "    if counter == 20:\n",
        "      break\n",
        "\n",
        "  return output_list"
      ],
      "metadata": {
        "id": "-GS6tBkx3s-N"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def EE_output_processing(org_output):\n",
        "  output = copy.deepcopy(org_output)\n",
        "  # remove empty list samples\n",
        "  output = [item for item in output if len(item.keys())>= 2]\n",
        "  return output"
      ],
      "metadata": {
        "id": "204sddU-l01n"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TE_SciERC_gold_samples_generator(dataset):\n",
        "\n",
        "  gold_samples = {}\n",
        "  for sample in dataset:\n",
        "    # gold_sample = {}\n",
        "    gold_samples[sample['id']] = [sample['h']['name'], sample['relation'],sample['t']['name']]\n",
        "    # gold_samples.append(gold_sample)\n",
        "  return gold_samples"
      ],
      "metadata": {
        "id": "4kofQ-h0fI8A"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TE_SciERC_evaluation(gold_samples, processed_output):\n",
        "  labels = []\n",
        "  predictions = []\n",
        "\n",
        "  for item in processed_output:\n",
        "    gold_sample_triple = gold_samples[item['id']]\n",
        "\n",
        "    relation = gold_sample_triple[1]\n",
        "    labels.append(relation)\n",
        "    flag = 0\n",
        "    for triple in item['Triples']:\n",
        "      print(\"{} <-> {}\\n{} <-> {}\\n{} <-> {}\\n *** \\n\".format(triple[0], gold_sample_triple[0], triple[1], gold_sample_triple[1], triple[2], gold_sample_triple[2]))\n",
        "      if triple[0] == gold_sample_triple[0] and triple[1] == gold_sample_triple[1] and triple[2] == gold_sample_triple[2]:\n",
        "        flag = 1\n",
        "      if relation in ['COMPARE', 'CONJUNCTION' ] and triple[2] == gold_sample_triple[0] and triple[1] == gold_sample_triple[1] and triple[0] == gold_sample_triple[2]:\n",
        "        flag = 1\n",
        "    if flag ==1:\n",
        "      predictions.append(relation)\n",
        "    else:\n",
        "      predictions.append('wrong')\n",
        "\n",
        "  return labels, predictions"
      ],
      "metadata": {
        "id": "p2exHFpvhKeD"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TE_metric_calculation(labels, predictions, event_labels):\n",
        "\n",
        "  # when predict an event which is not in gournd truth, we had wrong prediction which decreases our P.\n",
        "  # when we did not predict any event and there is an even in groundtruth, it deacreses our R.\n",
        "  # Thats why we put zeor both in ground truth and pred list to handle this inconsitency of number of extracted events.\n",
        "  micro_p = precision_score(labels,predictions, average='micro')*100.0\n",
        "  micro_r = recall_score(labels,predictions, average='micro')*100.0\n",
        "  micro_f1 = f1_score(labels,predictions,  average='micro')*100.0\n",
        "\n",
        "\n",
        "  print(\"Micro_F1:\",micro_f1)\n",
        "  print(\"Micro_Precision:\",micro_p)\n",
        "  print(\"Micro_Recall:\",micro_r)\n"
      ],
      "metadata": {
        "id": "4TXaozMmn0GU"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SciERC_gold_samples = TE_SciERC_gold_samples_generator(SciERC_dataset_40samples)"
      ],
      "metadata": {
        "id": "rq8nYtfogAqg"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ],
      "metadata": {
        "id": "egTRG4rjmnzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline Prompt"
      ],
      "metadata": {
        "id": "PIc6bioMmqbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paper_one_shot_prompt = '''\n",
        "\n",
        "The list of predicates: {}.\n",
        "What Subject-Predicate-Object triples are included in the following sentence? Please return the possible answers according to the list above. Require the answer only in the form: [subject, predicate, object]\n",
        "\n",
        "Example:\n",
        "The given sentence is :  We show that various features based on the structure of email-threads can be used to improve upon lexical similarity of discourse segments for question-answer pairing .\n",
        "Triples: [lexical similarity , FEATURE-OF , discourse segments]\n",
        "\n",
        "The given sentence is : {}\n",
        "Triples:\n",
        "'''"
      ],
      "metadata": {
        "id": "zQ43Y1dRmnbD"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = TE_prompt_runner(paper_one_shot_prompt, SciERC_dataset_40samples, list_of_relations)\n",
        "labels, predictions = TE_SciERC_evaluation(SciERC_gold_samples, output)\n",
        "TE_metric_calculation(labels, predictions, list_of_relation)"
      ],
      "metadata": {
        "id": "crFlgCS24ScF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f50cb703-9e03-4248-9d6c-5a5545b7f4d1"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learned confidence measures <-> outlier removal\n",
            "USED-FOR <-> PART-OF\n",
            "outlier removal <-> stereo vision\n",
            " *** \n",
            "\n",
            "learned confidence measures <-> outlier removal\n",
            "USED-FOR <-> PART-OF\n",
            "quality improvement <-> stereo vision\n",
            " *** \n",
            "\n",
            "car <-> detection task\n",
            "PART-OF <-> CONJUNCTION\n",
            "Savarese et al. 2007 and PASCAL VOC 2006 datasets <-> viewpoint classification task\n",
            " *** \n",
            "\n",
            "we <-> trees\n",
            "EVALUATE-FOR <-> CONJUNCTION\n",
            "various features <-> dags\n",
            " *** \n",
            "\n",
            "various features <-> trees\n",
            "FEATURE-OF <-> CONJUNCTION\n",
            "string <-> dags\n",
            " *** \n",
            "\n",
            "original image <-> visual quality\n",
            "PART-OF <-> EVALUATE-FOR\n",
            "benchmark data <-> state-of-the-art solutions\n",
            " *** \n",
            "\n",
            "quality <-> visual quality\n",
            "FEATURE-OF <-> EVALUATE-FOR\n",
            "original image <-> state-of-the-art solutions\n",
            " *** \n",
            "\n",
            "complex system <-> maximum-entropy model\n",
            "PART-OF <-> USED-FOR\n",
            "uncertainty <-> stochastic output selection\n",
            " *** \n",
            "\n",
            "named-entity recognition and linking <-> transfer component\n",
            "USED-FOR <-> PART-OF\n",
            "question answering <-> system\n",
            " *** \n",
            "\n",
            "named-entity recognition and linking <-> transfer component\n",
            "USED-FOR <-> PART-OF\n",
            "multi-document summarization <-> system\n",
            " *** \n",
            "\n",
            "named-entity recognition and linking <-> transfer component\n",
            "USED-FOR <-> PART-OF\n",
            "machine translation <-> system\n",
            " *** \n",
            "\n",
            "task of machine translation -LRB- MT -RRB- evaluation <-> machine translation -LRB- MT -RRB- evaluation\n",
            "RELATED-TO <-> CONJUNCTION\n",
            "task of sentence-level semantic equivalence classification <-> sentence-level semantic equivalence classification\n",
            " *** \n",
            "\n",
            "similarity <-> PASCAL VOC 2006 dataset\n",
            "FEATURE-OF <-> EVALUATE-FOR\n",
            "discourse segments <-> cascade evaluation\n",
            " *** \n",
            "\n",
            "cascade evaluation <-> method\n",
            "COMPARE <-> USED-FOR\n",
            "exhaustive procedure <-> search\n",
            " *** \n",
            "\n",
            "proposed method <-> method\n",
            "REQUIRE <-> USED-FOR\n",
            "evaluations of the classifier functions <-> search\n",
            " *** \n",
            "\n",
            "cost aggregation algorithm <-> algorithm\n",
            "USED-FOR <-> USED-FOR\n",
            "acts directly on our three-dimensional matching cost space <-> rendering of occlusions\n",
            " *** \n",
            "\n",
            "temporal maintenance of a background model <-> algorithm\n",
            "USED-FOR <-> USED-FOR\n",
            "enhance the rendering of occlusions and reduce temporal artefacts <-> rendering of occlusions\n",
            " *** \n",
            "\n",
            "part-of speech tags <-> heavy occlusion\n",
            "USED-FOR <-> CONJUNCTION\n",
            "improve the accuracy of the HMM-based part-of-speech tagger <-> camera motions\n",
            " *** \n",
            "\n",
            "geometric constraints <-> image information\n",
            "PART-OF <-> USED-FOR\n",
            "3-D stereo reconstruction scheme <-> 3 -- D shape\n",
            " *** \n",
            "\n",
            "image information <-> image information\n",
            "USED-FOR <-> USED-FOR\n",
            "recover 3-D shape <-> 3 -- D shape\n",
            " *** \n",
            "\n",
            "Video games <-> It\n",
            "USED-FOR <-> USED-FOR\n",
            "entertainment <-> unsupervised object discovery\n",
            " *** \n",
            "\n",
            "Video games <-> It\n",
            "USED-FOR <-> USED-FOR\n",
            "education <-> unsupervised object discovery\n",
            " *** \n",
            "\n",
            "size of new firms <-> technique\n",
            "COMPARE <-> USED-FOR\n",
            "size of the pre-existing firms <-> search algorithm\n",
            " *** \n",
            "\n",
            "Micro_F1: 0.0\n",
            "Micro_Precision: 0.0\n",
            "Micro_Recall: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Designed Prompt"
      ],
      "metadata": {
        "id": "p6DhQTCvpsWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(list_of_relations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0zp7gXfYnGf",
        "outputId": "84ff3274-fd78-4854-d3bc-a9fa496fb76c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['COMPARE', 'HYPONYM-OF', 'PART-OF', 'FEATURE-OF', 'USED-FOR', 'CONJUNCTION', 'EVALUATE-FOR']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_shot_prompt = '''\n",
        "The list of predicates: {}.\n",
        "Identify the Subject-Predicate-Object triples within the given sentence. Ensure that the order of subject, predicate, and object is accurately preserved. Provide your response exclusively in the format: Triples: [subject, predicate, object].\n",
        "\n",
        "Example:\n",
        "The given sentence is : Experimental results on our dataset and the public G3D dataset both demonstrate very promising performance of our scheme.\n",
        "Triples: [dataset, CONJUNCTION, G3D dataset]\n",
        "\n",
        "return at least one triple for below sentence.\n",
        "The given sentence is : {}\n",
        "Triples:\n",
        "'''"
      ],
      "metadata": {
        "id": "NGCIETmnpsB0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = TE_prompt_runner(one_shot_prompt, SciERC_dataset_40samples, list_of_relations)\n",
        "labels, predictions = TE_SciERC_evaluation(SciERC_gold_samples, output)\n",
        "TE_metric_calculation(labels, predictions, list_of_relation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "BG0ZFxEOkyzg",
        "outputId": "31a8f3be-4f8c-4225-9df7-d1ad2fc63139"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-f21dc33cfd55>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTE_prompt_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_shot_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSciERC_dataset_40samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_of_relations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTE_SciERC_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSciERC_gold_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTE_metric_calculation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_of_relation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-653ff2eec105>\u001b[0m in \u001b[0;36mTE_prompt_runner\u001b[0;34m(prompt_base, dataset, list_of_relations)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0;31m# print(output_list, idx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         return cast(\n\u001b[1;32m    165\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    167\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    542\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    543\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         flattened_outputs = [\n\u001b[1;32m    410\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 results.append(\n\u001b[0;32m--> 398\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    399\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    575\u001b[0m                 )\n\u001b[1;32m    576\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m                 return self._generate(\n\u001b[0m\u001b[1;32m    578\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         )\n\u001b[0;32m--> 555\u001b[0;31m         response: genai.types.GenerateContentResponse = _chat_with_retry(\n\u001b[0m\u001b[1;32m    556\u001b[0m             \u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mis_explicit_retry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTryAgain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_explicit_retry\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;31m# Do not retry for these errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFailedPrecondition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36msend_message\u001b[0;34m(self, content, generation_config, safety_settings, stream, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"candidate_count\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't chat with `candidate_count > 1`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         response = self.model.generate_content(\n\u001b[0m\u001b[1;32m    368\u001b[0m             \u001b[0mcontents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0mgeneration_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             )\n\u001b[0;32m--> 349\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_since_first_attempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1171\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_ready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             )\n\u001b[0;32m-> 1157\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m             \u001b[0m_handle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vFBCmFNZccaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COT Prompting"
      ],
      "metadata": {
        "id": "_tA_q2lJMtkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "\n",
        "Triple extraction Prompt:\n",
        "\n",
        "(1) extract the entities from the given sentence\n",
        "(2) identify potential relations between each pair of extracted entities, considering different head and tail combinations for each pair.\n",
        "(3) compare the predicted relation for each pair to the provided ground truths (including the option of \"no-relation\") to pinpoint its closest match\n",
        "(4) return the triples in the exact format of [head, relation, tail], separating them with commas.\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "8E2QjXvYccX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QlLbEv0uccS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lYgMIFiFccQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JaXiymJrccNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hrviG6H9ccKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SBo2tt7pccH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BI4SCqASccFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9cuhopI2ccCr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}